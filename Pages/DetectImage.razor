@page "/detectimage"
@using Microsoft.ML.OnnxRuntime
@using Microsoft.ML.OnnxRuntime.Tensors
@using SixLabors.ImageSharp
@using SixLabors.ImageSharp.PixelFormats
@using SixLabors.ImageSharp.Processing
@inject IWebHostEnvironment Env

<h3>Comparer 2 images</h3>

<div style="text-align: left; margin-top: 10px;">
    <InputFile OnChange="OnInputFile1" />
    <InputFile OnChange="OnInputFile2" />
    <button disabled="@(!CanCompare || isProcessing)" @onclick="CompareImages">
        Comparer
        @if (isProcessing)
        {
            <span class="spinner"></span>
        }
    </button>
</div>

<div style="display: flex; gap: 20px; align-items: flex-start;">
    <div style="text-align: center;">
        <p>@img1Error</p>
        @if (img1Preview != null)
        {
            <img src="@img1Preview" width="200" style="border: 1px solid #ccc; border-radius: 5px;" />
        }
    </div>

    <div style="text-align: center;">
        <p>@img2Error</p>
        @if (img2Preview != null)
        {
            <img src="@img2Preview" width="200" style="border: 1px solid #ccc; border-radius: 5px;" />
        }
    </div>
    @if (similarity.HasValue)
    {
        <div style="text-align: center; margin-top: 20px;">
            <p>
                <b>SimilaritÃ© :</b> 
                <span style="color:@GetSimilarityColor(similarity.Value)">
                    @similarity.Value.ToString("0.00") %
                </span>
            </p>
            <div style="width: 200px; height: 20px; border: 1px solid #ccc; border-radius: 5px; margin: 0 auto; background: #eee;">
                <div style="height: 100%; border-radius: 5px; background:@GetSimilarityColor(similarity.Value); width:@similarity.Value%"></div>
            </div>
        </div>
    }
</div>

@code {
    private IBrowserFile file1, file2;
    private string? img1Preview, img2Preview;
    private string? img1Error, img2Error;
    private float? similarity;
    private bool isProcessing = false;

    private bool CanCompare => file1 != null && file2 != null && string.IsNullOrEmpty(img1Error) && string.IsNullOrEmpty(img2Error);

    private async Task OnInputFile1(InputFileChangeEventArgs e)
    {
        try
        {
            similarity = null;
            img1Error = null;
            file1 = e.File;
            img1Preview = await ConvertToBase64Async(file1);
        }
        catch (Exception ex)
        {
            img1Error = ex.Message;
        }
    }

    private async Task OnInputFile2(InputFileChangeEventArgs e)
    {
        try
        {
            img2Error = null;
            similarity = null;
            file2 = e.File;
            img2Preview = await ConvertToBase64Async(file2);
        }
        catch (Exception ex)
        {
            img2Error = ex.Message;
        }
    }

    private async Task CompareImages()
    {
        try
        {
            isProcessing = true;   // Active le loader
            StateHasChanged();     // RafraÃ®chit l'UI

            var tempFile1 = await SaveBrowserFile(file1);
            var tempFile2 = await SaveBrowserFile(file2);

            similarity = CompareImagesWithOnnx(tempFile1, tempFile2);
        }
        finally
        {
            isProcessing = false;  // Cache le loader
            StateHasChanged();     // RafraÃ®chit l'UI
        }
    }

    private async Task<string> SaveBrowserFile(IBrowserFile file)
    {
        var tempPath = Path.Combine(Path.GetTempPath(), file.Name);
        using var fs = File.Create(tempPath);
        await file.OpenReadStream().CopyToAsync(fs);
        return tempPath;
    }

    private async Task<string> ConvertToBase64Async(IBrowserFile file)
    {
        using var stream = file.OpenReadStream(maxAllowedSize: 10_000_000);
        using var image = await Image.LoadAsync<Rgba32>(stream);
        using var ms = new MemoryStream();
        await image.SaveAsPngAsync(ms);
        return $"data:image/png;base64,{Convert.ToBase64String(ms.ToArray())}";
    }

    // Transforme une image en tenseur [1,3,224,224] normalisÃ©, prÃªt Ã  Ãªtre passÃ© dans le modÃ¨le CLIP ONNX.
    private DenseTensor<float> PreprocessImage(string imagePath)
    {
        // ðŸ”¹ 1. Charger l'image en mÃ©moire au format RGB (3 canaux)
        // Ici on force le type Rgb24 (8 bits par canal) â†’ plus simple pour normaliser ensuite.
        using var image = Image.Load<Rgb24>(imagePath);

        // ðŸ”¹ 2. Redimensionner l'image en 224x224 pixels (taille attendue par CLIP ViT-B/32)
        image.Mutate(x => x.Resize(224, 224));

        // ðŸ”¹ 3. CrÃ©er le tenseur de sortie au format attendu par ONNX : [batch, channels, height, width]
        // Ici batch = 1, channels = 3 (R,G,B), height = 224, width = 224
        var tensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });

        // ðŸ”¹ 4. Moyenne et Ã©cart-type spÃ©cifiques au modÃ¨le CLIP
        // Elles servent Ã  normaliser les pixels de l'image
        float[] mean = { 0.48145466f, 0.4578275f, 0.40821073f };
        float[] std = { 0.26862954f, 0.26130258f, 0.27577711f };

        // ðŸ”¹ 5. Remplir le tenseur avec les pixels normalisÃ©s
        for (int y = 0; y < 224; y++)
        {
            for (int x = 0; x < 224; x++)
            {
                // RÃ©cupÃ©rer le pixel Ã  la position (x,y)
                var pixel = image[x, y];

                // Normaliser chaque canal :
                //   (valeur/255 - moyenne) / Ã©cart-type
                tensor[0, 0, y, x] = (pixel.R / 255f - mean[0]) / std[0]; // Rouge
                tensor[0, 1, y, x] = (pixel.G / 255f - mean[1]) / std[1]; // Vert
                tensor[0, 2, y, x] = (pixel.B / 255f - mean[2]) / std[2]; // Bleu
            }
        }

        // ðŸ”¹ 6. Retourner le tenseur prÃªt Ã  Ãªtre donnÃ© au modÃ¨le ONNX
        return tensor;
    }

    // Calcule un score indiquant Ã  quel point deux vecteurs pointent dans la mÃªme direction, donc leur similaritÃ©
    private float CosineSimilarity(float[] a, float[] b)
    {
        float dot = 0, magA = 0, magB = 0;
        for (int i = 0; i < a.Length; i++)
        {
            dot += a[i] * b[i];
            magA += a[i] * a[i];
            magB += b[i] * b[i];
        }
        return dot / ((float)Math.Sqrt(magA) * (float)Math.Sqrt(magB));
    }

    // PrÃ©traite deux images, passe leurs tenseurs dans le modÃ¨le CLIP ONNX pour obtenir leurs embeddings, puis retourne leur similaritÃ© cosinus en pourcentage
    private float CompareImagesWithOnnx(string file1Path, string file2Path)
    {
        string modelPath = Path.Combine(Env.WebRootPath, "models/openai.clip-vit-base-patch32.onnx");

        using var session = new InferenceSession(modelPath);

        var tensor1 = PreprocessImage(file1Path);
        var tensor2 = PreprocessImage(file2Path);

        // Placeholders texte (seq_len = 77 pour CLIP)
        var inputIds = new DenseTensor<long>(new int[] { 1, 77 });
        var attentionMask = new DenseTensor<long>(new int[] { 1, 77 });

#if DEBUG
    foreach (var input in session.InputMetadata)
            Console.WriteLine($"{input.Key}: {input.Value.ElementType} {string.Join(",", input.Value.Dimensions)}");
// input_ids: System.Int64 -1,-1
// pixel_values: System.Single -1,-1,-1,-1
// attention_mask: System.Int64 -1,-1

        foreach (var output in session.OutputMetadata)
            Console.WriteLine(output.Key);
// logits_per_image
// logits_per_text
// text_embeds
// image_embeds
#endif

        var inputs1 = new List<NamedOnnxValue>
        {
            NamedOnnxValue.CreateFromTensor("pixel_values", tensor1),
            NamedOnnxValue.CreateFromTensor("input_ids", inputIds),
            NamedOnnxValue.CreateFromTensor("attention_mask", attentionMask)
        };

        var inputs2 = new List<NamedOnnxValue>
        {
            NamedOnnxValue.CreateFromTensor("pixel_values", tensor2),
            NamedOnnxValue.CreateFromTensor("input_ids", inputIds),
            NamedOnnxValue.CreateFromTensor("attention_mask", attentionMask)
        };

        float[] embedding1;
        float[] embedding2;

        // Demande au modÃ¨le de donner son vecteur de reprÃ©sentation (embedding) de lâ€™image.
        // Cet embedding est un vecteur de 512 flottants (dimension dÃ©pendante du modÃ¨le CLIP).
        using (var results1 = session.Run(inputs1))
        {
            embedding1 = results1
                .First(x => x.Name == "image_embeds")   // ðŸ”¹ sÃ©lectionne la sortie du modÃ¨le qui s'appelle "image_embeds"
                .AsTensor<float>()                      // ðŸ”¹ convertit en tenseur de float
                .ToArray();                             // ðŸ”¹ aplati en tableau C# float[]
        }

        using (var results2 = session.Run(inputs2))
        {
            embedding2 = results2.First(x => x.Name == "image_embeds").AsTensor<float>().ToArray();
        }

        return CosineSimilarity(embedding1, embedding2) * 100;
    }

    private string GetSimilarityColor(float value)
    {
        // Simple gradient: rouge (<50%), orange (50-80%), vert (>80%)
        if (value < 50) return "#e74c3c";      // rouge
        if (value < 80) return "#f39c12";      // orange
        return "#2ecc71";                      // vert
    }
}

<style>
    .spinner {
        border: 4px solid #f3f3f3;
        border-top: 4px solid #3498db;
        border-radius: 50%;
        width: 24px;
        height: 24px;
        animation: spin 1s linear infinite;
        display: inline-block;
        vertical-align: middle;
        margin-left: 8px;
    }

    @@keyframes spin {
        0% {
            transform: rotate(0deg);
        }

        100% {
            transform: rotate(360deg);
        }
    }
</style>
